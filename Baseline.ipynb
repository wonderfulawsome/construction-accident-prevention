{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\82106\\Desktop\\데이콘 한솔데크\\data\\train.csv\"\n",
    "train = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\82106\\Desktop\\데이콘 한솔데크\\data\\test.csv\"\n",
    "test = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\82106\\Desktop\\데이콘 한솔데크\\data\\sample_submission.csv\"\n",
    "sample = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                              고소 작업 추락 위험 부위 안전 장비 설치\n",
      "1                                  재발 방지 대책 마련 안전교육 실시\n",
      "2            현장 자재 정리 안전 관리 철저 재발 방지 대책 공문 발송 향후 조치 계획\n",
      "3    위험성 평가 교육 작업장 위험 요인 안전 수칙 근로자 전파 근로자 안전교육 강화 사...\n",
      "4    자재 정리 작업 세부 작업 방법 교육 실시 작업 구간 이동 경로 점검 장애물 사전 ...\n",
      "Name: 재발방지대책 및 향후조치계획, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import re\n",
    "import string\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "with open('C:/Users/82106/Desktop/데이콘 한솔데크/불용어.txt', 'r', encoding = 'UTF-8') as f:\n",
    "  list_file = f.readlines() \n",
    "stopwords = list_file[0].split(\",\")\n",
    "\n",
    "# 정규화\n",
    "def preprocess(text):\n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', ' ', str(text).strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    "\n",
    "# 명사/영단어 추출, 한글자 제외, 불용어 제거\n",
    "def remove_stopwords(text):\n",
    "    n = []\n",
    "    word = komoran.nouns(text)\n",
    "    p = komoran.pos(text)\n",
    "    for pos in p:\n",
    "      if pos[1] in ['SL']:\n",
    "        word.append(pos[0])\n",
    "    for w in word:\n",
    "      if len(w)>1 and w not in stopwords:\n",
    "        n.append(w)\n",
    "    return \" \".join(n)\n",
    "\n",
    "# 최종\n",
    "def finalpreprocess(text):\n",
    "  return remove_stopwords(preprocess(text))\n",
    "\n",
    "# 전처리 및 불용어 제거 적용 (두 단계)\n",
    "train[\"재발방지대책 및 향후조치계획\"] = train[\"재발방지대책 및 향후조치계획\"].apply(finalpreprocess)\n",
    "\n",
    "# 결과 확인\n",
    "print(train[\"재발방지대책 및 향후조치계획\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82106\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\82106\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:195: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v4 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(jhgan/ko-sbert-sts) 불러오기\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts', use_auth_token=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인적사고에 따른 재발방지대책 임베딩 및 대표 대책 인덱스 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09eedd022cef46c7a1eff38844138f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped = train.groupby(\"인적사고\")\n",
    "\n",
    "res = {}\n",
    "cosine_res = []\n",
    "for name, group in tqdm(grouped):\n",
    "    plan = group[\"재발방지대책 및 향후조치계획\"]\n",
    "    vectors = np.stack(plan.apply(model.encode).to_numpy())\n",
    "    similarity = cosine_similarity(vectors, vectors)    \n",
    "    cosine_res += similarity[similarity.mean(axis=1).argmax()].tolist()\n",
    "    res[name] = plan.iloc[similarity.mean(axis=1).argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 히스토그램에 따른 임베딩 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 0.0 - 0.1: 0개\n",
      "Range 0.1 - 0.2: 6개\n",
      "Range 0.2 - 0.3: 116개\n",
      "Range 0.3 - 0.4: 581개\n",
      "Range 0.4 - 0.5: 1838개\n",
      "Range 0.5 - 0.6: 4416개\n",
      "Range 0.6 - 0.7: 8572개\n",
      "Range 0.7 - 0.8: 6871개\n",
      "Range 0.8 - 0.9: 958개\n",
      "Range 0.9 - 1.0: 21개\n"
     ]
    }
   ],
   "source": [
    "arr = cosine_res\n",
    "\n",
    "# 0.1 단위로 구간을 지정\n",
    "bins = np.arange(0, 1.1, 0.1)  # 0.0 ~ 1.0을 0.1 간격으로 나눔\n",
    "\n",
    "# 히스토그램 계산\n",
    "hist, bin_edges = np.histogram(arr, bins=bins)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(len(hist)):\n",
    "    print(f\"Range {bin_edges[i]:.1f} - {bin_edges[i+1]:.1f}: {hist[i]}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대표 대책 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_v = {}\n",
    "for k,v in res.items():\n",
    "    res_v[k] = model.encode(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 데이터에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    accident = test.loc[i, \"인적사고\"]\n",
    "    sample.loc[i, \"재발방지대책 및 향후조치계획\"] = res[accident]\n",
    "    sample.iloc[i, 2:] = res_v[accident]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"C:/Users/82106/Desktop/데이콘 한솔데크/data/result/baseline.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
